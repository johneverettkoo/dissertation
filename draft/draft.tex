% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{setspace}
\usepackage{float}
\usepackage{mathtools}
\usepackage{natbib}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\setcitestyle{numbers,square,comma}
\usepackage{verbatim}
\usepackage{amsthm}
\usepackage{comment}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

\doublespacing

\pagenumbering{gobble}

%\begin{titlepage}
\begin{center}
\LARGE{\textsc{Community Detection in the Setting of Generalized Random Dot Product Graphs}}\\
\vspace*{6\baselineskip}
\normalsize{John Koo}\\
\vspace*{10\baselineskip}
\singlespacing
\normalsize{Submitted to the faculty of the Univesity Graduate School \\
in partial fulfillment of the requirements for the degree \\
Doctor of Philosophy \\
in the Department of Statistics, \\
Indiana University \\
December 2022}
\vspace*{3\baselineskip}

\end{center}

\pagenumbering{roman}
\thispagestyle{empty}

\newpage

\singlespacing

Accepted by the Graduate Faculty, Indiana University, in partial fulfillment of the requirements for the degree of Doctor of Philosophy.

\vspace*{6\baselineskip}

\begin{tabular}{@{}p{1in}p{4in}@{}}
Approved: & \hrulefill \\
& Michael W. Trosset, Ph.D. \\
\\
\\
& \hrulefill \\
& Minh Tang, Ph.D. \\
\\
\\
& \hrulefill \\
& Julia Fukuyama, Ph.D. \\
\\
\\
& \hrulefill \\
& Roni Khardon, Ph.D. \\
\\
\\
& \hrulefill \\
& Fangzheng Xie, Ph.D. \\
\end{tabular}

\vspace*{16\baselineskip}

\raggedright

December 1, 2022

\newpage

\doublespacing

\begin{center}
\LARGE{\bf{Acknowledgements}}
\end{center}

\hypersetup{linkcolor = black}

\newpage

\begin{center}
\LARGE{Abstract}
\end{center}

\vspace*{2\baselineskip}

\normalsize

Graph and network data, in which samples are represented not as a collection of feature vectors but as relationships between pairs of observations, are increasingly widespread in various fields ranging from sociology to computer vision. One common goal of analyzing graph data is community detection or graph clustering, in which the graph is partitioned into disconnected subgraphs in an unsupervised yet meaningful manner (e.g., by optimizing an objective function or recovering unobserved labels). Because traditional clustering techniques were developed for data that can be represented as vectors, they cannot be applied directly to graphs. In this research, we investigate the use of a family of spectral decomposition based approaches for community detection in block models (random graph models with inherent community structure), first by demonstrating how under the Generalized Random Dot Product Graph framework, all graphs generated by block models can be represented as feature vectors, then applying clustering methods for these feature vector representations, and finally deriving the asymptotic properties of these methods. 

\newpage
\tableofcontents
\addcontentsline{toc}{section}{\contentsname}

\newpage
\pagenumbering{arabic}
\hypersetup{linkcolor = blue}

\newcommand{\diag}{\mathrm{diag}}
\newcommand{\tr}{\mathrm{Tr}}
\newcommand{\blockdiag}{\mathrm{blockdiag}}
\newcommand{\indep}{\stackrel{\mathrm{ind}}{\sim}}
\newcommand{\iid}{\stackrel{\mathrm{iid}}{\sim}}
\newcommand{\Bernoulli}{\mathrm{Bernoulli}}
\newcommand{\Betadist}{\mathrm{Beta}}
\newcommand{\BG}{\mathrm{BernoulliGraph}}
\newcommand{\Uniform}{\mathrm{Uniform}}
\newcommand{\PABM}{\mathrm{PABM}}
\newcommand{\RDPG}{\mathrm{RDPG}}
\newcommand{\GRDPG}{\mathrm{GRDPG}}
\newcommand{\Multinomial}{\mathrm{Multinomial}}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\as}{\stackrel{\mathrm{a.s.}}{\to}}
\newcommand{\ER}{\text{Erd\"{o}s-R\'{e}nyi}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{graphs-and-representations-of-network-data}{%
\subsection{Graphs and Representations of Network
Data}\label{graphs-and-representations-of-network-data}}

Graph and network data have become increasingly widespread in various
fields including sociology, neuroscience, biostatistics, and computer
science. This has resulted in various challenges for researchers who
rely on traditional statistical and machine learning methods that are
incompatible with graph data and instead assume that the data exist as
feature vectors. To illustrate this challenge, consider the typical
approach to building a statistical or machine learning model. Data are
often represented as an \(n \times p\) matrix
\(X = \begin{bmatrix} x_1 & \cdots & x_n \end{bmatrix}^\top\) in which
each row \(x_i \in \mathbb{R}^p\) is a vector of \(p\) features and each
column is a set of \(n\) feature measurements. An analysis task for
these data might be to come up with a classification model
\(\phi : \mathbb{R}^p \to \{1, 2, ..., K\}\) that uses the numerical
values of each feature of a vector. For instance, \(\phi(x)\) might
first compute the distance from \(x\) to one of \(K\) points in
\(\mathbb{R}^p\) and assign \(x\) to the label of the nearest point.
Examples of this include linear discriminant analysis (in the case of
supervised learning) and Lloyd's algorithm or Gaussian mixture models
(in the case of unsupervised learning). However, this type of approach
is incompatible with data that are represented as graphs, in which each
observation is not a vector of numerical features but a set of
relationships to other observations. Instead of feature vector
\(x_i = \begin{bmatrix} x_{i1} & \cdots & x_{ip} \end{bmatrix}^\top\),
we observe
\(a_i = \begin{bmatrix} a_{i1} & \cdots & a_{in} \end{bmatrix}\) where
each \(a_{ij}\) is object \(i\)'s relationship to object \(j\).

A more formal description of graph data is as follows: Suppose we
observe a network of \(n\) objects and pairwise relationships between
them. This network is represented by a graph object \(G = (V, E)\) with
vertex set \(V\), representing the objects, and edge set \(E\),
representing the pairwise relationships. The numeric representation of
these data is in the form of \emph{affinity matrix}
\(A \in \mathbb{R}^{n \times n}\) in which each \(A_{ij}\) is object
\(i\)'s relationship to object \(j\). We assume that the entries of
\(A\) represent affinities or similarities, i.e., the higher the value
of \(A_{ij}\), the stronger the relationship \(i\) has to \(j\). If
\(A_{ij} = 0\), then \(i\) has no direct relationship to \(j\). \(A\) is
symmetric if it represents an undirected graph in which the relationship
from \(i\) to \(j\) is the same as the relationship from \(j\) to \(i\).
\(A\) is binary, i.e., \(A \in \{0, 1\}^{n \times n}\), if it represents
an unweighted graph in which edges either exist or don't exist. If \(A\)
is binary, we call it an \emph{adjacency matrix}.

\hypertarget{probabilistic-models-for-graphs}{%
\subsection{Probabilistic Models for
Graphs}\label{probabilistic-models-for-graphs}}

Given a sample or dataset, a typical analysis tasks are statistical
inference, or the estimation of various parameters assuming the data
come from a random distribution or process. These estimated parameters
are often then used for making predictions or deriving insights about
the population. For example, when fitting a Gaussian mixture model, the
data are first assumed to come from a mixture of Gaussians. The model
fitting process then involves estimating the means and standard
deviations of each Gaussian component, along with the mixture weights.
The resulting model provides insight into where each mixture component
is located, how disperse each component is, and how the data are
distributed between the components, as well as a prediction for which
mixture a new observation belongs to. In order to perform a similar type
of analysis for graphs, we must first define probability distributions
from which such data can be sampled.

Within the scope of this dissertation, we focus primarily on unweighted
and undirected graphs without self-loops. The adjacency matrix that
describes such a graph is binary, symmetric, and hollow. In this
setting, a plausible model is to sample each edge independently from a
Bernoulli distribution, i.e., \(A_{ij} \indep P_{ij}\) for some
\(P_{ij} \in [0, 1]\) for each \(i < j\) (setting \(A_{ji} = A_{ij}\)
since \(A\) is symmetric, and \(A_{ii} = 0\) since \(A\) is hollow).
Then similar to how the edges are compiled into an adjacency matrix
\(A\), the edge probabilities can be compiled into an edge probability
matrix \(P \in [0, 1]^{n \times n}\). In order to provide structure

\hypertarget{block-models-for-community-detection}{%
\subsection{Block Models for Community
Detection}\label{block-models-for-community-detection}}

\hypertarget{the-stochastic-block-model}{%
\subsubsection{The Stochastic Block
Model}\label{the-stochastic-block-model}}

\hypertarget{generalizations-of-the-stochastic-block-model-the-degree-corrected-block-model-and-the-popularity-adjusted-block-model}{%
\subsubsection{Generalizations of the Stochastic Block Model: the Degree
Corrected Block Model and the Popularity Adjusted Block
Model}\label{generalizations-of-the-stochastic-block-model-the-degree-corrected-block-model-and-the-popularity-adjusted-block-model}}

\hypertarget{review-of-likelihood-maximization-approaches-to-block-models}{%
\subsubsection{Review of Likelihood Maximization Approaches to Block
Models}\label{review-of-likelihood-maximization-approaches-to-block-models}}

\newpage

\hypertarget{random-dot-product-graphs-and-generalized-random-dot-product-graphs}{%
\section{Random Dot Product Graphs and Generalized Random Dot Product
Graphs}\label{random-dot-product-graphs-and-generalized-random-dot-product-graphs}}

\hypertarget{definitions}{%
\subsection{Definitions}\label{definitions}}

\hypertarget{connecting-the-stochastic-block-model-to-the-generalized-random-dot-product-graph}{%
\subsection{Connecting the Stochastic Block Model to the Generalized
Random Dot Product
Graph}\label{connecting-the-stochastic-block-model-to-the-generalized-random-dot-product-graph}}

\hypertarget{connecting-the-degree-corrected-block-model-to-the-generalized-random-dot-product-graph}{%
\subsection{Connecting the Degree Corrected Block Model to the
Generalized Random Dot Product
Graph}\label{connecting-the-degree-corrected-block-model-to-the-generalized-random-dot-product-graph}}

\newpage

\hypertarget{popularity-adjusted-block-models-are-generalized-random-dot-product-graphs}{%
\section{Popularity Adjusted Block Models are Generalized Random Dot
Product
Graphs}\label{popularity-adjusted-block-models-are-generalized-random-dot-product-graphs}}

\newpage

\hypertarget{generalized-random-dot-product-graphs-with-community-structure}{%
\section{Generalized Random Dot Product Graphs with Community
Structure}\label{generalized-random-dot-product-graphs-with-community-structure}}

\newpage

\section*{Appendix A}

\newpage

\renewcommand\refname{References}
  \bibliography{bibliography.bib}

\end{document}
