---
title: |
  | Community Detection for the 
  | Generalized Random Dot Product Graph
subtitle: Dissertation Prospectus
author: John Koo
institution: Indiana University
output:
  pdf_document:
    keep_tex: true
    citation_package: natbib
    number_sections: yes
fontsize: 11pt
# geometry: "left=1in,right=1in,top=1in,bottom=1in"
urlcolor: blue
header-includes:
- \usepackage{setspace}
- \usepackage{float}
- \usepackage{mathtools}
- \usepackage{natbib}
- \usepackage[linesnumbered,ruled,vlined]{algorithm2e} 
- \setcitestyle{numbers,square,comma}
- \usepackage{verbatim}
- \usepackage{amsthm}
- \usepackage{comment}
bibliography: proposal.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      # eval = FALSE,
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 3, 
                      fig.width = 5, 
                      fig.dpi = 300)

options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')

import::from(magrittr, `%>%`)
library(ggplot2)
```

\newcommand{\diag}{\text{diag}}
\newcommand{\tr}{\text{Tr}}
\newcommand{\blockdiag}{\text{blockdiag}}
\newcommand{\indep}{\stackrel{\text{ind}}{\sim}}
\newcommand{\iid}{\stackrel{\text{iid}}{\sim}}
\newcommand{\Bernoulli}{\text{Bernoulli}}
\newcommand{\Betadist}{\text{Beta}}
\newcommand{\BG}{\text{BernoulliGraph}}
\newcommand{\Cat}{\text{Categorical}}
\newcommand{\GRDPG}{\text{GRDPG}}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{example}
\newtheorem*{example}{Example}

Graph and network data, in which samples are represented not as a collection of feature vectors but as relationships between pairs of observations, are increasingly widespread in various fields ranging from sociology to computer vision. One common goal of analyzing graph data is community detection or graph clustering, in which the graph is partitioned into disconnected subgraphs in an unsupervised yet meaningful manner (e.g., by optimizing an objective function or recovering unobserved labels). Because traditional clustering techniques were developed for data that can be represented as vectors, they cannot be applied directly to graphs. Common examples of such clustering techniques include $K$-means clustering \cite{1056489} and Gaussian Mixture Models \cite{doi:10.1198/016214502760047131}. In addition, these techniques assume that the vectors are sampled from a specific type of distribution (whether implicitly in the case of $K$-means clustering or explicitly in the case of GMM). In this research, we investigate the use of a family of spectral decomposition based approaches for community detection in block models (random graph models with inherent community structure). First, we demonstrate that under the Generalized Random Dot Product Graph \cite{rubindelanchy2017statistical} framework, all graphs generated by Block Models (generative graph models with inherent community structure) can be represented as collections of vectors in Euclidean space via the Adjacency Spectral Embedding \cite{athreya2017statistical, lyzinski2014}. Then, noting the particular structure or configuration that the vectors take, we select appropriate clustering techniques to apply on the vector representation of the graph. Finally we derive the asymptotic properties of these methods to show that our methods are consistent or achieve desirable properties with high probability. To illustrate this approach, we primarily focus on the Popularity Adjusted Block Model \cite{307cbeb9b1be48299388437423d94bf1}. 

Our work is essentially about connecting two well-known families of generative graph models, the Block Model and the (Generalized) Random Dot Product Graph \cite{rubindelanchy2017statistical} in order to perform community detection. It is straightforward to show that all Block Models are various cases of the GRDPG. This fact has been leveraged to develop community detection methods \cite{athreya2017statistical, lyzinski2014, rubindelanchy2017statistical} for the Stochastic Block Model \cite{doi:10.1080/0022250X.1971.9989788} and Degree Corrected Block Model \cite{Karrer_2011}. Our work begins by extending this to the Popularity Adjusted Block Model. We show that under the GRDPG framework, the latent configuration that generates the PABM consists of orthogonal subspaces. Then we show that two community detection algorithms arise naturally from this latent configuration: Orthogonal Spectral Clustering, which is an algorithm of our own design, and an existing algorithm, Sparse Subspace Clustering \cite{5206547}. We then extend this work to more general configurations in the latent space that imply community structure. The overall goal of our research is to develop a general framework or approach to community detection for a wide range of Block Models. 

\newpage

The overall generative model for inducing community structure can be described by the following.

Let $(A, X) \sim \GRDPG_{p, q}(F, n)$ such that:

1. Define functions $\gamma_1, ..., \gamma_K$ such that each 
$\gamma_k : [0, 1]^r \mapsto \mathbb{R}^d$ and $\gamma_k(t) \neq \gamma_l(t)$ 
when $k \neq l$.
2. Sample labels
$Z_1, ..., Z_n \iid \Cat(\pi_1, ..., \pi_K)$.
3. Sample $T_1, ..., T_n \iid D$ with support $[0, 1]^r$. 
4. Set latent positions $X_i = \gamma_{Z_i}(T_i)$ and 
$X = \begin{bmatrix} X_1 & \cdots & X_n \end{bmatrix}^\top$.
5. $A \sim \BG(X I_{p, q} X^\top)$

The SBM, DCBM, and PABM are all special cases of this generative model. Based on the structure of the $\gamma_k$ functions that correspond to each of the SBM, DCBM, and PABM, there are clear choices for clustering algorithms on the embeddings of each of these Block Models. Extensions of these results may consider which clustering algorithms result in consistent estimators given restrictions on each of the $\gamma_k$, and how to approach community detection when $\gamma_k$ are unknown altogether. 

The estimated timeline of completion is as follows:

1. Literature review and proofs of main theorems: December 2022

2. Simulations, real data analyses, R package: March 2022

3. Dissertation Completion: April 2022